

<!DOCTYPE html>
<html lang="en-us">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="robots" content="noodp" /><title>Code预训练语言模型学习指南（原理/分析/代码）Part1 - Qiushi</title><meta name="Description" content=""><meta property="og:title" content="Code预训练语言模型学习指南（原理/分析/代码）Part1" />
<meta property="og:description" content="Code预训练语言模型学习指南（原理/分析/代码）Part1" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://qiushisun.github.io/blog-posts/posts/2022-7-codeptms-review1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-06T20:00:03+00:00" />
<meta property="article:modified_time" content="2022-07-06T20:00:03+00:00" />
<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Code预训练语言模型学习指南（原理/分析/代码）Part1"/>
<meta name="twitter:description" content="Code预训练语言模型学习指南（原理/分析/代码）Part1"/>
      <meta name="twitter:site" content="@qiushi_sun"/>
<meta name="application-name" content="DoIt">
<meta name="apple-mobile-web-app-title" content="DoIt">

<meta name="theme-color" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><meta name="twitter:creator" content="@qiushi_sun" /><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">

<link rel="canonical" href="https://qiushisun.github.io/blog-posts/posts/2022-7-codeptms-review1/" /><link rel="next" href="https://qiushisun.github.io/blog-posts/posts/2022-7-codeptms-review2/" />
<link rel="stylesheet" href="/blog-posts/css/main.min.css"><link rel="stylesheet" href="/blog-posts/css/style.min.css"><link rel="preload" as="style" onload="this.onload=null;this.rel='stylesheet'" href="/blog-posts/lib/animate/animate.min.css">
        <noscript><link rel="stylesheet" href="/blog-posts/lib/animate/animate.min.css"></noscript><script type="application/ld+json">{"@context": "https://schema.org","@type": "BlogPosting",
        "headline": "Code预训练语言模型学习指南（原理/分析/代码）Part1",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https://qiushisun.github.io/blog-posts/posts/2022-7-codeptms-review1/"
        },"genre": "posts","keywords":["CodePTMs"],"wordcount":  285 ,
        "url": "https://qiushisun.github.io/blog-posts/posts/2022-7-codeptms-review1/","datePublished": "2022-07-06T20:00:03+00:00","dateModified": "2022-07-06T20:00:03+00:00","publisher": {
            "@type": "Organization",
            "name": "Author"},"author": {
                "@type": "Person",
                "name": "Author",
                "url": "/blog-posts/"
            },"description": ""
    }</script></head>

<body header-desktop="" header-mobile=""><script type="text/javascript">
        function setTheme(theme) {
          document.body.setAttribute('theme', theme); 
          document.documentElement.style.setProperty('color-scheme', theme === 'light' ? 'light' : 'dark');
          if (theme === 'light') {
            document.documentElement.classList.remove('tw-dark')
          } else {
            document.documentElement.classList.add('tw-dark')
          }
          window.theme = theme;   
          window.isDark = window.theme !== 'light' 
        }
        function saveTheme(theme) {window.localStorage && localStorage.setItem('theme', theme);}
        function getMeta(metaName) {const metas = document.getElementsByTagName('meta'); for (let i = 0; i < metas.length; i++) if (metas[i].getAttribute('name') === metaName) return metas[i]; return '';}
        if (window.localStorage && localStorage.getItem('theme')) {let theme = localStorage.getItem('theme');theme === 'light' || theme === 'dark' || theme === 'black' ? setTheme(theme) : (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? setTheme('dark') : setTheme('light')); } else { if ('' === 'light' || '' === 'dark' || '' === 'black') setTheme(''), saveTheme(''); else saveTheme('auto'), window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches ? setTheme('dark') : setTheme('light');}
        let metaColors = {'light': '#f8f8f8','dark': '#252627','black': '#000000'}
        getMeta('theme-color').content = metaColors[document.body.getAttribute('theme')];
        window.switchThemeEventSet = new Set()
    </script>
    <div id="back-to-top"></div>
    <div id="mask"></div><div class="wrapper"><header class="desktop print:!tw-hidden" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/blog-posts/" title="Qiushi">Qiushi</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item"
                    href="/blog-posts/links/" > Friends </a><a class="menu-item"
                    href="/blog-posts/about/" > About </a><span class="menu-item delimiter"></span><button class="menu-item theme-switch" aria-label="Switch Theme">
                    <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705 0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg>
                </button></div>
        </div>
    </div>
</header><header class="mobile print:!tw-hidden" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/blog-posts/" title="Qiushi">Qiushi</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/blog-posts/links/" title="" >Friends</a><a class="menu-item" href="/blog-posts/about/" title="" >About</a><button class="menu-item theme-switch tw-w-full" aria-label="Switch Theme">
                <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M8 256c0 136.966 111.033 248 248 248s248-111.034 248-248S392.966 8 256 8 8 119.033 8 256zm248 184V72c101.705 0 184 82.311 184 184 0 101.705-82.311 184-184 184z"/></svg>
            </button></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div><main class="main">
            <div class="container"><article class="page single print:!tw-w-full print:!tw-max-w-none print:!tw-m-0 print:!tw-p-0"><h1 class="single-title animate__animated animate__flipInX">Code预训练语言模型学习指南（原理/分析/代码）Part1</h1><div class="post-meta">
            <div class="post-meta-line">
                <span class="post-author"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M248 8C111 8 0 119 0 256s111 248 248 248 248-111 248-248S385 8 248 8zm0 96c48.6 0 88 39.4 88 88s-39.4 88-88 88-88-39.4-88-88 39.4-88 88-88zm0 344c-58.7 0-111.3-26.6-146.5-68.2 18.8-35.4 55.6-59.8 98.5-59.8 2.4 0 4.8.4 7.1 1.1 13 4.2 26.6 6.9 40.9 6.9 14.3 0 28-2.7 40.9-6.9 2.3-.7 4.7-1.1 7.1-1.1 42.9 0 79.7 24.4 98.5 59.8C359.3 421.4 306.7 448 248 448z"/></svg><a href="/blog-posts/" title="Author" rel=" author" class="author">Author</a>
                </span>&nbsp;<span class="post-category">included in </span>&nbsp;<span class="post-category">categories <a href="/blog-posts/categories/nlp/"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>NLP</a>&nbsp;<a href="/blog-posts/categories/code-intelligence/"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M464 128H272l-54.63-54.63c-6-6-14.14-9.37-22.63-9.37H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V176c0-26.51-21.49-48-48-48zm0 272H48V112h140.12l54.63 54.63c6 6 14.14 9.37 22.63 9.37H464v224z"/></svg>Code Intelligence</a></span></div>
            <div class="post-meta-line"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M148 288h-40c-6.6 0-12-5.4-12-12v-40c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v40c0 6.6-5.4 12-12 12zm108-12v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 96v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm-96 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm192 0v-40c0-6.6-5.4-12-12-12h-40c-6.6 0-12 5.4-12 12v40c0 6.6 5.4 12 12 12h40c6.6 0 12-5.4 12-12zm96-260v352c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h48V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h128V12c0-6.6 5.4-12 12-12h40c6.6 0 12 5.4 12 12v52h48c26.5 0 48 21.5 48 48zm-48 346V160H48v298c0 3.3 2.7 6 6 6h340c3.3 0 6-2.7 6-6z"/></svg>&nbsp;<time datetime="2022-07-06">2022-07-06</time>&nbsp;<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1 0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7 0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174L402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7l-43.2-43.2c-4.1-4.1-10.8-4.1-14.8 0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg>&nbsp;<time datetime="2022-07-06">2022-07-06</time>&nbsp;<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M497.9 142.1l-46.1 46.1c-4.7 4.7-12.3 4.7-17 0l-111-111c-4.7-4.7-4.7-12.3 0-17l46.1-46.1c18.7-18.7 49.1-18.7 67.9 0l60.1 60.1c18.8 18.7 18.8 49.1 0 67.9zM284.2 99.8L21.6 362.4.4 483.9c-2.9 16.4 11.4 30.6 27.8 27.8l121.5-21.3 262.6-262.6c4.7-4.7 4.7-12.3 0-17l-111-111c-4.8-4.7-12.4-4.7-17.1 0zM124.1 339.9c-5.5-5.5-5.5-14.3 0-19.8l154-154c5.5-5.5 14.3-5.5 19.8 0s5.5 14.3 0 19.8l-154 154c-5.5 5.5-14.3 5.5-19.8 0zM88 424h48v36.3l-64.5 11.3-31.1-31.1L51.7 376H88v48z"/></svg>&nbsp;285 words&nbsp;<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm0 448c-110.5 0-200-89.5-200-200S145.5 56 256 56s200 89.5 200 200-89.5 200-200 200zm61.8-104.4l-84.9-61.7c-3.1-2.3-4.9-5.9-4.9-9.7V116c0-6.6 5.4-12 12-12h32c6.6 0 12 5.4 12 12v141.7l66.8 48.6c5.4 3.9 6.5 11.4 2.6 16.8L334.6 349c-3.9 5.3-11.4 6.5-16.8 2.6z"/></svg>&nbsp;2 minutes&nbsp;</div>
        </div><div class="content" id="content"><p>Code预训练语言模型学习指南（原理/分析/代码）Part1</p>
<h2 id="introduction" class="headerLink">
    <a href="#introduction" class="header-mark"></a>Introduction</h2><p>自从2020年CodeBERT开了代码表征预训练模型（本文称之为CodePTM）这个新坑后，在短短两年的时间内出现了若干个程序设计语言（Programming Language，称之为PL，与Natural Language，也就是NL对应）语言模型。它们的共同特点是大部分用于处理PL（或Source Code）时所采用的技术是从NLP中的Transformer-based模型迁移而来，但这些CodePTMs又各有特点，从训练的角度出发即不同的预训练/微调策略，从数据的角度出发，比如是否使用了代码的结构信息，即抽象语法树（Abstract Syntax Tree，本文将其简称为AST）及其变体。而从架构出发，这些Code预训练模型大致可以被分为以下这三类：</p>
<ol>
<li>encoder-only：CuBERT、CodeBERT、GraphCodeBERT等</li>
<li>decoder-only：CodeGPT、GPT-C等</li>
<li>encoder-decoder：PLBART、CodeT5等</li>
</ol>
<p>本文对各个CodePTM建模编程语言的思想进行回顾，并简要分析了一下它们的特色。对文中提到的所有CodePTMs的描述主要从背景、预训练策略、微调策略以及下游任务这几个角度出发进行分析，考虑到这些模型之间都存在一些共性以及文章篇幅原因，文中略去了一些通用的处理手段和细节，因此对各部分的分析讲解详略不一，不过都保留了建模编程语言最核心的思想。阅读前需要对Transformer有一定的了解，考虑到单篇博客的长度，这些模型分在两篇博客中讲完。</p>
<h2 id="cubert" class="headerLink">
    <a href="#cubert" class="header-mark"></a>CuBERT</h2><p>ICML 2020 <a href="https://arxiv.org/abs/2001.00059" target="_blank" rel="noopener noreferrer">Learning and Evaluating Contextual Embedding of Source Code</a></p>
<p>CuBERT，即Code Understanding BERT，和后面提到的CodeBERT可被归为同一个时期的工作，虽是首个提出Code预训练模型的工作，但和CodeBERT相比，其影响力较小（我在写这篇文章的时候CuBERT引用还没过百），具体原因个人认为是它仅对Python语言进行建模（CodeBERT同时对6种编程语言建模），且它的下游任务和CodeBERT相比不太丰富，主要是以代码理解任务为主。</p>
<p>作者通过GitHub采集了7.4M Python语言编写的程序用于CuBERT的预训练，将基于Transformer类模型处理自然语言的手段迁移到了编程语言上，使用的模型架构和训练方式直接照搬了BERT-Large（24层16个注意力头），然后使用了一个处理过的<a href="https://github.com/google-research-datasets/eth_py150_open" target="_blank" rel="noopener noreferrer">ETH Py150</a>数据集进行微调。</p>
<p>与此同时，作者还训练了一组Word2Vec embeddings、Bi-LSTM模型和Transformer模型用于比较。</p>
<p>就任务而言，作者构建了一个Benchmark，其中包含了：</p>
<ol>
<li>五个分类任务（具体细节和描述可参考原文附录）
<ol>
<li>Variable-Misuse Classification</li>
<li>Wrong Binary Operator</li>
<li>Swapped Operand</li>
<li>Function-Docstring Mismatch</li>
<li>Exception Type</li>
</ol>
</li>
<li>一个定位+修复任务（Variable-Misuse Localization and Repair），也是本文唯一一个非分类任务</li>
</ol>
<p>就这几个下游任务而言，可以看到CuBERT主要还是在做代码理解领域的判别式任务，与后续出现的CodeXGLUE Benchmark比其在任务的数量和类型上都有局限性。而且，由于它仅采用了Python语言，和后面出现的各种CodePTMs比局限性比较大，因此仅做简单的科普。</p>
<h2 id="codebert" class="headerLink">
    <a href="#codebert" class="header-mark"></a>CodeBERT</h2><p>Findings of EMNLP 2020 <a href="https://aclanthology.org/2020.findings-emnlp.139/" target="_blank" rel="noopener noreferrer">CodeBERT: A Pre-Trained Model for Programming and Natural Languages</a></p>
<p>相比前面提到同期工作的CuBERT，CodeBERT的影响力比它大很多。一方面是因为它是多语言（multi-programming-lingual）模型，纳入了6个编程语言，另一方面是它和MSRA自己的CodeXGLUE Benchmark配套后在各个下游任务上被广泛使用。</p>
<p>除了预训练阶段的任务有变化外，CodeBERT的其他方面与自然语言中的BERT模型训练基本无异（其本质上的一个RoBERTa），CodeBERT使用了bimodal data（即PL-NL Pairs）进行了预训练，预训练数据的来源为CodeSearchNet数据集，其中有Python, Java, JavaScript, PHP, Ruby和Go这六种编程语言的2.1M bimodal data和6.4M unimodal codes（也就是没有对应comments的纯代码），这些数据的来源都是GitHub中的开源仓库，并且后续的很多工作也在预训练阶段用了CodeSearchNet数据集。</p>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/codesearchnet-data.png"
        srcset="2022-7-CodePTMs-Review/codesearchnet-data.png, 2022-7-CodePTMs-Review/codesearchnet-data.png 1.5x, 2022-7-CodePTMs-Review/codesearchnet-data.png 2x"
        title="CodeSearchNet" ><figcaption class="image-caption">codesearchnet-data</figcaption>
    </figure></p>
<p>CodeBERT的输入形式为 $[CLS], w_1, w_2, &hellip;w_n, [SEP], c_1, c_2, &hellip;, c_m, [EOS]$，第一段为自然语言文本，第二段为代码，训练的数据可分为两种，即bimodal data，即NL-PL Pairs和unimodal data，也就是纯代码。</p>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/codebert-code-with-NL.png"
        srcset="2022-7-CodePTMs-Review/codebert-code-with-NL.png, 2022-7-CodePTMs-Review/codebert-code-with-NL.png 1.5x, 2022-7-CodePTMs-Review/codebert-code-with-NL.png 2x"
        title="Bomodal Data" ><figcaption class="image-caption">Bomodal Data</figcaption>
    </figure></p>
<p><strong>Masked Language Modeling (MLM)</strong>，算是Transformer类模型的预训练中最老生常谈的任务了，作者将其应用于基于bimodal data的训练</p>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/codebert-mlm.png"
        srcset="2022-7-CodePTMs-Review/codebert-mlm.png, 2022-7-CodePTMs-Review/codebert-mlm.png 1.5x, 2022-7-CodePTMs-Review/codebert-mlm.png 2x"
        title="Masked Language Modeling" ><figcaption class="image-caption">Masked Language Modeling</figcaption>
    </figure></p>
<p><strong>Replaced Token Detection (RTD)</strong>，迁移自ELECTRA，既可以利用bimodal data进行训练，还可以进一步利用unimodal data（比如是没有对应自然语言文本的code），具体细节可以参考ELECTRA原文。</p>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/codebert-rtd.png"
        srcset="2022-7-CodePTMs-Review/codebert-rtd.png, 2022-7-CodePTMs-Review/codebert-rtd.png 1.5x, 2022-7-CodePTMs-Review/codebert-rtd.png 2x"
        title="Replaced Token Detection" ><figcaption class="image-caption">Replaced Token Detection</figcaption>
    </figure></p>
<p>实验部分做了Natural Language Code Search，个人认为文中没有添加更多下游任务是受到EMNLP的篇幅限制，使用CodeBERT可以在多个下游任务，如Clone detection（克隆检测）、Defect detection（缺陷检测）、Code summarization等上得到出色的结果，具体可参考CodeXGLUE，如下图所示</p>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/CodeXGLUE-benchmark.jpg"
        srcset="2022-7-CodePTMs-Review/CodeXGLUE-benchmark.jpg, 2022-7-CodePTMs-Review/CodeXGLUE-benchmark.jpg 1.5x, 2022-7-CodePTMs-Review/CodeXGLUE-benchmark.jpg 2x"
        title="CodeXGLUE Benchmark" ><figcaption class="image-caption">CodeXGLUE Benchmark</figcaption>
    </figure></p>
<p>从CodeBERT开始，后续的CodePTMs就全部继承了对多个PL的支持，不过CodeBERT完全使用了建模自然语言的手段来为Code（或是说NL-PL Pairs）做预训练，忽视了代码的一个很大的特性，那就是结构信息，具体而言就是在编译器进行语法分析阶段生成的抽象语法树（Abstract Syntax Tree，本文称之为AST），紧跟着CodeBERT的GraphCodeBERT立刻填上了这个坑。</p>
<h2 id="graphcodebert" class="headerLink">
    <a href="#graphcodebert" class="header-mark"></a>GraphCodeBERT</h2><p>ICLR2021 <a href="https://iclr.cc/Conferences/2021/Schedule?showEvent=2598" target="_blank" rel="noopener noreferrer">GRAPHCODEBERT: PRE-TRAINING CODE REPRESENTATIONS WITH DATA FLOW</a></p>
<p>看名字就知道这是CodeBERT的后续工作，主要想法就是为CodeBERT添加代码的语法信息，使CodePTM可以显式学习代码的结构信息。</p>
<p>GraphCodeBERT基于数据流学习代码的表征，如下图所示</p>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/graphcodebert-extracting-data-flow.png"
        srcset="2022-7-CodePTMs-Review/graphcodebert-extracting-data-flow.png, 2022-7-CodePTMs-Review/graphcodebert-extracting-data-flow.png 1.5x, 2022-7-CodePTMs-Review/graphcodebert-extracting-data-flow.png 2x"
        title="GraphCodeBERT所使用的数据流" ><figcaption class="image-caption">Extracting Data Flow</figcaption>
    </figure></p>
<p>数据流的获得分为以下几个步骤</p>
<ol>
<li>通过语法分析工具获得AST，原文中使用的工具是tree-sitter</li>
<li>从AST中提出变量，构成一个由变量组成的序列</li>
<li>从AST中抽取变量之间的依赖关系，文中称之为“value comes from”，构造数据流图</li>
</ol>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/graphcodebert-pt.png"
        srcset="2022-7-CodePTMs-Review/graphcodebert-pt.png, 2022-7-CodePTMs-Review/graphcodebert-pt.png 1.5x, 2022-7-CodePTMs-Review/graphcodebert-pt.png 2x"
        title="GraphCodeBERT的预训练" ><figcaption class="image-caption">GCB Pretraining</figcaption>
    </figure></p>
<p>GraphCodeBERT在模型预训练阶段额外提出了两个在当时较为新颖的训练任务</p>
<ol>
<li>Edge Prediction，即数据流图边预测，通过预测数据流图的边学习代码的结构信息</li>
<li>Node Alignment，即变量对齐，具体而言是学习数据流图中的某个node来自输入代码中的哪个code token
将它们和从CodeBERT（或是BERT or RoBERTa）继承下来的MLM任务一起优化。考虑到AST是一种图结构，为了让Transformer能适应其与一般序列结构的差异，作者修改了其注意力机制，主要是通过调整Attention Mask缩小感受野。</li>
</ol>
<p>{% raw %}
$$
\begin{equation}M_{i j}= \begin{cases}0 &amp; \text { if } q_{i} \in{[C L S],[S E P]} \text { or } q_{i}, k_{j} \in W \cup C \text { or }\left\langle q_{i}, k_{j}\right\rangle \in E \cup E^{\prime} \ -\infty &amp; \text { otherwise }\end{cases}\end{equation}
$$
{% endraw %}</p>
<p>作者将其称为Graph-Guided Masked Attention，其中E代表的是数据流图的边，E&rsquo;代表的是数据流图的节点和代码的对应关系边。</p>
<p>就下游任务而言，GraphCodeBERT文中主要完成了Natural Language Code Search、Clone Detection、Code Translation和Code Refinement这几个任务，它同样适用CodeXGLUE Benchmark中的其他任务，比如Code Summarization等。</p>
<p>GraphCodeBERT相较于前作CodeBERT解决了CodePTM只学习自然语义，而不学代码结构/语法的问题。但细心的读者或许能发现，学习数据流相较于学习AST本身有相当的信息损失，这也为之后的UniXcoder挖了一个小坑。</p>
<h2 id="gpt-c" class="headerLink">
    <a href="#gpt-c" class="header-mark"></a>GPT-C</h2><p>FSE/ESEC 2020 <a href="https://dl.acm.org/doi/10.1145/3368089.3417058" target="_blank" rel="noopener noreferrer">IntelliCode Compose: Code Generation using Transformer</a></p>
<p>GPT-C是为了代码补全（Code Completion）这个任务而设计的，作者认为之前的的代码补全工作有两点不同</p>
<ol>
<li>根据上文的token来预测下个token，没有将代码的全文环境纳入考虑</li>
<li>多语言效果不佳</li>
</ol>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/GPT-C-Code-Completion.png"
        srcset="2022-7-CodePTMs-Review/GPT-C-Code-Completion.png, 2022-7-CodePTMs-Review/GPT-C-Code-Completion.png 1.5x, 2022-7-CodePTMs-Review/GPT-C-Code-Completion.png 2x"
        title="Code Completion" ><figcaption class="image-caption">GPT-C Code Completion</figcaption>
    </figure></p>
<p>作者提出的GPT-C是GPT-2模型的变体，在一个大规模、无监督、多语言的数据集上从零开始训练。基于GPT-C，作者构建了一个代码补全Framework，称之为IntelliCode Compose，并对多种编程语言进行建模。作者将Sequence decoding的过程视为对树的搜索，搜到出现目标token为止。</p>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/GPT-C-code-snippet.png"
        srcset="2022-7-CodePTMs-Review/GPT-C-code-snippet.png, 2022-7-CodePTMs-Review/GPT-C-code-snippet.png 1.5x, 2022-7-CodePTMs-Review/GPT-C-code-snippet.png 2x"
        title="Sequence decoding" ><figcaption class="image-caption">GPT-C Sequence decoding</figcaption>
    </figure></p>
<p>虽说是多语言，但是使用的是Python, C#, JavaScript 和 TypeScript，和CodeXGLUE不同且少了两个语言。</p>
<p>就多语言模型的训练而言，作者提出了四个训练的策略</p>
<ol>
<li>Language-agnostic baseline，即忽略掉编程语言的不同构建一个baseline多语言模型。</li>
<li>Language-type embedding，即加入一个向量来表示每种编程语言，和token embedding等相加。</li>
<li>Language specific control codes，每个输入的训练样本前拼接一个&quot;lang ∗ remaining token sequence”字符串，∗即为编程语言</li>
<li>add a programming language classification task during model pretraining，即在预训练阶段加入一个分类编程语言的任务</li>
</ol>
<p>关于IntelliCode Compose：作者将Sequence decoding的过程视为对树的搜索，搜到出现目标token为止</p>
<p><figure><img
        
        loading="lazy"
        src="2022-7-CodePTMs-Review/GPT-C-ablation.png"
        srcset="2022-7-CodePTMs-Review/GPT-C-ablation.png, 2022-7-CodePTMs-Review/GPT-C-ablation.png 1.5x, 2022-7-CodePTMs-Review/GPT-C-ablation.png 2x"
        title="multilingual modeling approaches based on GPT-C" ><figcaption class="image-caption">GPT-C Ablation</figcaption>
    </figure></p>
<p>在文末，作者考虑到了模型的推理开销问题，还上了一个知识蒸馏，并且还讨论了一下模型基于K8S和VS Code的部署问题。</p>
<h2 id="code-gpt" class="headerLink">
    <a href="#code-gpt" class="header-mark"></a>Code-GPT</h2><p>Code-GPT是在CodeXGLUE中被提出的，没有单独成文，不要和GPT-C搞混了。作者实现它的目的是为了code completion 和 text-to-code generation任务。它就是一个由Code训练，与GPT-2完全同架构的12层Transformer Decoder模型，不过MSRA的研究者实现了两个版本</p>
<ol>
<li>Pretrained from scratch：随机初始化，从零训练</li>
<li>CodeGPT-adapted：先使用一个GPT-2作为起始点，再持续使用Code进行训练，作者将这个方法称为“domain-adaptive”</li>
</ol>
<p>更详细的内容可以参考CodeXGLUE原文的4.2节，作者在Huggingface提供了<a href="https://huggingface.co/microsoft/CodeGPT-small-java" target="_blank" rel="noopener noreferrer">CodeGPT-small-java</a> 和 <a href="https://huggingface.co/microsoft/CodeGPT-small-java-adaptedGPT2" target="_blank" rel="noopener noreferrer">CodeGPT-small-java-adaptedGPT2</a> 这两个checkpoints，正常地使用transformers库加载就能使用了。</p>
<p>以上是5个代码表征领域的预训练模型的简介与简要分析，还有若干模型会在下一篇博客中继续讨论。</p></div>

        <div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2022-07-06</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line print:!tw-hidden">
            <div class="post-info-md"></div>
            <div class="post-info-share"></div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M497.941 225.941L286.059 14.059A48 48 0 0 0 252.118 0H48C21.49 0 0 21.49 0 48v204.118a48 48 0 0 0 14.059 33.941l211.882 211.882c18.744 18.745 49.136 18.746 67.882 0l204.118-204.118c18.745-18.745 18.745-49.137 0-67.882zM112 160c-26.51 0-48-21.49-48-48s21.49-48 48-48 48 21.49 48 48-21.49 48-48 48zm513.941 133.823L421.823 497.941c-18.745 18.745-49.137 18.745-67.882 0l-.36-.36L527.64 323.522c16.999-16.999 26.36-39.6 26.36-63.64s-9.362-46.641-26.36-63.64L331.397 0h48.721a48 48 0 0 1 33.941 14.059l211.882 211.882c18.745 18.745 18.745 49.137 0 67.882z"/></svg>&nbsp;<a href="/blog-posts/tags/ptms/">PTMs</a>,&nbsp;<a href="/blog-posts/tags/codelms/">CodeLMs</a></section>
        <section class="print:!tw-hidden">
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/blog-posts/">Home</a></span>
        </section>
    </div>

    <div class="post-nav print:tw-hidden">
            <a href="/blog-posts/posts/2022-7-codeptms-review2/" class="next" rel="next" title="Code预训练语言模型学习指南（原理/分析/代码）Part2">Code预训练语言模型学习指南（原理/分析/代码）Part2<svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a></div>
</div>
</article></div>
        </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">
                    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreferrer" title="Hugo 0.124.1">Hugo</a>&nbsp;|&nbsp;Theme - <a href="https://github.com/HEIGE-PCloud/DoIt" target="_blank" rel="noopener noreferrer" title="DoIt 0.4.0"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M402.3 344.9l32-32c5-5 13.7-1.5 13.7 5.7V464c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V112c0-26.5 21.5-48 48-48h273.5c7.1 0 10.7 8.6 5.7 13.7l-32 32c-1.5 1.5-3.5 2.3-5.7 2.3H48v352h352V350.5c0-2.1.8-4.1 2.3-5.6zm156.6-201.8L296.3 405.7l-90.4 10c-26.2 2.9-48.5-19.2-45.6-45.6l10-90.4L432.9 17.1c22.9-22.9 59.9-22.9 82.7 0l43.2 43.2c22.9 22.9 22.9 60 .1 82.8zM460.1 174L402 115.9 216.2 301.8l-7.3 65.3 65.3-7.3L460.1 174zm64.8-79.7l-43.2-43.2c-4.1-4.1-10.8-4.1-14.8 0L436 82l58.1 58.1 30.9-30.9c4-4.2 4-10.8-.1-14.9z"/></svg> DoIt</a>
                </div><div class="footer-line"><svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 8C119.033 8 8 119.033 8 256s111.033 248 248 248 248-111.033 248-248S392.967 8 256 8zm0 448c-110.532 0-200-89.451-200-200 0-110.531 89.451-200 200-200 110.532 0 200 89.451 200 200 0 110.532-89.451 200-200 200zm107.351-101.064c-9.614 9.712-45.53 41.396-104.065 41.396-82.43 0-140.484-61.425-140.484-141.567 0-79.152 60.275-139.401 139.762-139.401 55.531 0 88.738 26.62 97.593 34.779a11.965 11.965 0 0 1 1.936 15.322l-18.155 28.113c-3.841 5.95-11.966 7.282-17.499 2.921-8.595-6.776-31.814-22.538-61.708-22.538-48.303 0-77.916 35.33-77.916 80.082 0 41.589 26.888 83.692 78.277 83.692 32.657 0 56.843-19.039 65.726-27.225 5.27-4.857 13.596-4.039 17.82 1.738l19.865 27.17a11.947 11.947 0 0 1-1.152 15.518z"/></svg>2024<span class="author">&nbsp;<a href="/blog-posts/" target="_blank" rel="noopener noreferrer"></a></span></div>
            <div class="footer-line"></div>
            <div class="footer-line">
            </div>
        </div></footer></div>

    <div id="fixed-buttons" class="print:!tw-hidden"><a href="#back-to-top" id="back-to-top-button" class="fixed-button" title="Back to Top">
            <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M34.9 289.5l-22.2-22.2c-9.4-9.4-9.4-24.6 0-33.9L207 39c9.4-9.4 24.6-9.4 33.9 0l194.3 194.3c9.4 9.4 9.4 24.6 0 33.9L413 289.4c-9.5 9.5-25 9.3-34.3-.4L264 168.6V456c0 13.3-10.7 24-24 24h-32c-13.3 0-24-10.7-24-24V168.6L69.2 289.1c-9.3 9.8-24.8 10-34.3.4z"/></svg>
        </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
            <svg class="icon"
    xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!-- Font Awesome Free 5.15.4 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) --><path d="M256 32C114.6 32 0 125.1 0 240c0 49.6 21.4 95 57 130.7C44.5 421.1 2.7 466 2.2 466.5c-2.2 2.3-2.8 5.7-1.5 8.7S4.8 480 8 480c66.3 0 116-31.8 140.6-51.4 32.7 12.3 69 19.4 107.4 19.4 141.4 0 256-93.1 256-208S397.4 32 256 32z"/></svg>
        </a>
    </div><div class="assets"><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{}};</script><script
    src="/blog-posts/lib/clipboard/clipboard.min.js"
    
  ></script><script
    src="/blog-posts/js/theme.min.js"
    
      defer
    
  ></script></div>
</body>

</html>
